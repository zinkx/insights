# An introduction to activation functions
add introduction here
## Overview of common activation functions

### **sigmoid**
$f(x) = \frac{1}{1+e^{-x}}$
![sigmoid sketch](sigmoid.png "sigmoid")
### **tanh**
$f(x) = tanh(x)$
![tanh sketch](tanh.png "tanh")
### **ReLU**
$f(x) = max(0,x)$
![ReLU sketch](ReLU.png "ReLU")
### **leaky ReLU**
$f(x;\alpha) = max(\alpha x,x)$
![leaky ReLU sketch](leaky_ReLU.png "leaky ReLU")

